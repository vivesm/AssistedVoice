server:
  type: ollama
  host: host.docker.internal
  port: 11434
  timeout: 30
  retry_attempts: 3
  lm_studio:
    api_key: not-needed
    base_url: /v1
whisper:
  mode: "remote"              # Options: local, remote
  remote_url: "http://192.168.7.224:5001/transcribe" # URL for remote transcription
  model: "small"              # Options: tiny, base, small, medium, large, turbo
  language: "en"              # Language code (en, es, fr, etc.)
  device: "auto"              # auto, cpu, cuda, mps (Metal Performance Shaders)
  compute_type: "int8"        # int8 for Apple Silicon, float16 for CUDA GPUs
  
# Language Model (Ollama)
ollama:
  model: "llama3.2:latest"     # Model name (using available model)
  vision_model: "qwen3-vl"    # Vision-capable model for image inputs
  fallback_model: "mistral:latest"  # Fallback option
  temperature: 0.7            # Response randomness (0.0-1.0)
  max_tokens: 500             # Maximum response length
  context_window: 4096        # Context size
  system_prompt: |
    You are a helpful voice assistant. Keep responses concise and natural for speech.
    Avoid using markdown, special characters, or formatting that doesn't work well when spoken aloud.
    Be conversational and friendly.

lm_studio:

  model: openai/gpt-oss-20b
  fallback_model: qwen/qwen3-32b
  temperature: 0.7
  max_tokens: 800
  context_window: 8192
  system_prompt: 'You are a helpful voice assistant. Keep responses concise and natural
    for speech.

    Avoid using markdown, special characters, or formatting that doesn''t work well
    when spoken aloud.

    Be conversational and friendly.

    '
ui:
  mode: text
  theme: default
  show_timestamps: true
  show_latency: true
  clear_on_start: true
audio:
  input_device: null
  sample_rate: 16000
  channels: 1
  chunk_duration: 0.5
  silence_threshold: 500
vad:
  enabled: true
  mode: 2
  speech_timeout: 1.5
  min_speech_duration: 0.5
hotkeys:
  push_to_talk: space
  toggle_mode: m
  clear_history: c
  exit: q
logging:
  level: INFO
  file: logs/assistant.log
  max_size: 10MB
  backup_count: 3
performance:
  response_streaming: true
  cache_responses: true
  max_cache_size: 100
  parallel_processing: true
stt:
  type: whisper
  model: small
  language: en
  device: cpu
  compute_type: int8
tts:
  engine: edge-tts
  voice: en-US-JennyNeural
  rate: +0%
  volume: +40%
  edge_voice: en-US-JennyNeural
reading_mode:
  enabled: true
  max_text_length: 200000
  chunk_size: 500
  auto_advance: true
  share_base_url: https://share.vives.io
  fetch_timeout: 10
